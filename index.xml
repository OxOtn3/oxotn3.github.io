<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>耶宵夜</title>
        <link>https://example.com/</link>
        <description>Recent content on 耶宵夜</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Thu, 28 Apr 2022 16:08:25 +0800</lastBuildDate><atom:link href="https://example.com/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>基于OpenTSDB搭建Grafana监控实践</title>
        <link>https://example.com/p/grafana/</link>
        <pubDate>Thu, 28 Apr 2022 16:08:25 +0800</pubDate>
        
        <guid>https://example.com/p/grafana/</guid>
        <description>&lt;h2 id=&#34;whats-opentsdb&#34;&gt;What&amp;rsquo;s OpenTSDB&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;OpenTSDB consists of a &lt;strong&gt;Time Series Daemon (TSD)&lt;/strong&gt; as well as set of command line utilities. Interaction with OpenTSDB is primarily achieved by running one or more of the TSDs. Each TSD is independent. There is no master, no shared state so you can run as many TSDs as required to handle any load you throw at it. Each TSD uses the open source database HBase or hosted Google Bigtable service to store and retrieve time-series data. The data schema is highly optimized for fast aggregations of similar time series to minimize storage space. Users of the TSD never need to access the underlying store directly. You can communicate with the TSD via a simple telnet-style protocol, an HTTP API or a simple built-in GUI. All communications happen on the same port (the TSD figures out the protocol of the client by looking at the first few bytes it receives).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看下官网给出的架构图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vurtneatfield.oss-cn-shanghai.aliyuncs.com/img/tsdb-architecture.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;infra&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;重点就是基于HBase的分布式的时间序列数据库，所以非常适合做监控系统。&lt;/p&gt;
&lt;h2 id=&#34;grafana搭建监控&#34;&gt;Grafana搭建监控&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;首先Grafana监控是基于Metrics打点实现的，可以参考其他的文档，这里不再赘述。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;Metric&lt;/code&gt; ：打点的tag&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Aggregator&lt;/code&gt; ：可以选择sum/average等&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Alias&lt;/code&gt; ：取名，可以通过${&amp;hellip;}的方式获取Filters/Tags以及Variables中的变量，下面会提到&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Downsampling&lt;/code&gt; ：降采样，官方文档解释为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Downsampling (or in signal processing, &lt;em&gt;decimation&lt;/em&gt;) is the process of reducing the sampling rate, or resolution, of data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实很好理解，看下开启Downsampling前后的两张对比图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vurtneatfield.oss-cn-shanghai.aliyuncs.com/img/downsampling-before.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;before downsampling&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://vurtneatfield.oss-cn-shanghai.aliyuncs.com/img/downsampling-after.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
		alt=&#34;after downsampling&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;很明显，使用Downsampling之后的采样数据在降低了采样率的情况下，依然能够表现出与原采样结构较吻合的曲线走势。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Filters&lt;/code&gt; 和 &lt;code&gt;Tags&lt;/code&gt; ：其实这两个是类似的概念，但需要注意二者不能同时使用，并且Tags也在OpenTSDB2.2之后就deprecated了，所以我们这里使用Filters。实际上，Filters功能也的确更加丰富。&lt;/p&gt;
&lt;p&gt;大多数情况下，我们的监控需求都可以通过Filters实现，那么下面就来详细介绍一下Filters的用法。&lt;/p&gt;
&lt;p&gt;Filters内置的过滤器有以下几种：&lt;/p&gt;
&lt;h3 id=&#34;literal_or&#34;&gt;literal_or&lt;/h3&gt;
&lt;p&gt;Takes a single literal value or a &lt;code&gt;|&lt;/code&gt; pipe delimited list of values and returns any time series matching the results on a case sensitive bases. This is a very efficient filter as it can resolve the strings to UIDs and send that to the storage layer for pre-filtering. In SQL this is similar to the &lt;code&gt;IN&lt;/code&gt; or &lt;code&gt;=&lt;/code&gt; predicates.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Examples&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;host=literal_or(web01|web02|web03)&lt;/code&gt; In SQL: &lt;code&gt;WHERE host IN (&#39;web01&#39;, &#39;web02&#39;, &#39;web03&#39;)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host=literal_or(web01)&lt;/code&gt; In SQL: &lt;code&gt;WHERE host = &#39;web01&#39;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;iliteral_or&#34;&gt;iliteral_or&lt;/h3&gt;
&lt;p&gt;The same as a &lt;code&gt;literal_or&lt;/code&gt; but is case insensitive. Note that this is not efficient like the literal or as it must post-process all rows from storage.&lt;/p&gt;
&lt;h3 id=&#34;not_literal_or&#34;&gt;not_literal_or&lt;/h3&gt;
&lt;p&gt;Case sensitive &lt;code&gt;literal_or&lt;/code&gt; that will return series that do &lt;strong&gt;NOT&lt;/strong&gt; match the given list of values. Efficient as it can be pre-processed by storage.&lt;/p&gt;
&lt;h3 id=&#34;not_iliteral_or&#34;&gt;not_iliteral_or&lt;/h3&gt;
&lt;p&gt;Case insensitive &lt;code&gt;not_literal_or&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&#34;wildcard&#34;&gt;wildcard&lt;/h3&gt;
&lt;p&gt;Provides case sensitive postfix, prefix, infix and multi-infix filtering. The wildcard character is an asterisk (star) &lt;code&gt;*&lt;/code&gt;. Multiple wildcards can be used. If only the asterisk is given, the filter effectively returns any time series that include the tag key (and is an efficient filter that can be pre-processed). In SQL land, this is similar to &lt;code&gt;LIKE&lt;/code&gt; predicate with a bit more flexibility.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Examples&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;host=wildcard(*mysite.com)&lt;/code&gt; In SQL: &lt;code&gt;WHERE host=&#39;%mysite.com&#39;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host=wildcard(web*)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host=wildcard(web*mysite.com)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host=wildcard(web*mysite*)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;host=wildcard(*)&lt;/code&gt; This is equivalent to the v1 basic group by operator and is efficient.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;iwildcard&#34;&gt;iwildcard&lt;/h3&gt;
&lt;p&gt;The same as &lt;code&gt;wildcard&lt;/code&gt; but case insensitive.&lt;/p&gt;
&lt;h3 id=&#34;regexp&#34;&gt;regexp&lt;/h3&gt;
&lt;p&gt;Filters using POSIX compliant regular expressions post fetching from storage. The filter uses Java’s built-in regular expression operation. Be careful to escape special characters depending on the query method used.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Examples&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;regexp(web.*)&lt;/code&gt; In SQL: &lt;code&gt;WHERE host REGEXP &#39;web.*&#39;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;regexp(web[0-9].mysite.com)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总结一下，大多数情况下使用literal_or/not_literal_or/wildcard即可，并且这样也效率更高。有忽略大小写的需求以及支持正则表达式的需求可以使用剩下的几种。&lt;/p&gt;
&lt;p&gt;这里还有一个很细的点，v2.1即之前只有 | 和 * 可用，区别在于：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In the original OpenTSDB release and up to 2.1, only two types of filters were available and they were implicitly configured for grouping. The two operators allowed were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;***** - The asterisk (or &lt;em&gt;wildcard&lt;/em&gt;) will return a separate result for each unique tag value detected. E.g. if the tag key &lt;code&gt;host&lt;/code&gt; was paired with &lt;code&gt;web01&lt;/code&gt; and &lt;code&gt;web02&lt;/code&gt; then there would be two groups emitted, one on &lt;code&gt;web01&lt;/code&gt; and one on &lt;code&gt;web02&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;|&lt;/strong&gt; - The pipe (or &lt;em&gt;literal_or&lt;/em&gt;) will return a separate result &lt;em&gt;only&lt;/em&gt; for the exact tag values specified. I.e. it will match only time series with the given tag value and group on each of those matches.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Multiple filters can be provided per query and the results are always &lt;em&gt;ANDed&lt;/em&gt; together. These filters are still available for use in 2.x and later.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我的理解里大概意思是，* 占位符会为每种结果单独统计，而 | 的使用将会将所有可能取值聚合在一起。（不知道对不对）&lt;/p&gt;
&lt;p&gt;了解完这些之后，基本就能满足我们的过滤需求了，那么我们可以通过${&amp;hellip;}的方式让Alias更加直观。有这么两种方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过Filters中的Key直接指定，例如 &lt;code&gt;${tag_country}&lt;/code&gt; 指代country的取值。&lt;strong&gt;需要注意的是&lt;/strong&gt;，这种方法在使用Filters时，只有当 &lt;code&gt;groupBy = true&lt;/code&gt; 时才能正确读取，原因其实很简单，因为只有 groupBy = true 时才会聚合曲线；而使用Tags时没有这一问题。&lt;/li&gt;
&lt;li&gt;通过配置Variables中变量指定，例如 &lt;code&gt;${country}&lt;/code&gt; 指代country的值，是的，这里无需加上 &lt;code&gt;tag_&lt;/code&gt; 前缀。&lt;strong&gt;需要注意的是&lt;/strong&gt;，当配置变量为K-V对时，这种方法读取的是Value。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;基于OpenTSDB，通过我们的Metrics打点，在了解了Filters原理以及使用方法后，我们便能够很好地在Grafana上搭建符合我们需求的监控大盘了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;参考&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;http://opentsdb.net/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;OpenTSDB官方文档&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>Algo Diary</title>
        <link>https://example.com/p/algo-diary/</link>
        <pubDate>Tue, 05 Apr 2022 18:19:05 +0800</pubDate>
        
        <guid>https://example.com/p/algo-diary/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;medium做多，hard做精，easy做稳&lt;/p&gt;
&lt;p&gt;—3.28 洗澡时有感&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;content&#34;&gt;Content&lt;/h2&gt;
&lt;h3 id=&#34;graph&#34;&gt;Graph&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Dijkstra&lt;/p&gt;
&lt;p&gt;3.30 ~ 4.2&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Topological Sort&lt;/p&gt;
&lt;p&gt;4.3 ~ 4.4&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;common&#34;&gt;Common&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Enumeration&lt;/p&gt;
&lt;p&gt;4.5&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Binary Search&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Segment Tree&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;string&#34;&gt;String&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Brute Force&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;KMP&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;dp&#34;&gt;DP&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;DP&lt;/li&gt;
&lt;li&gt;Greedy&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;328&#34;&gt;3.28&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/heaters/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;475. 供暖器&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;很像我字节二面的算法题&lt;/p&gt;
&lt;p&gt;排序+二分遍历能过&lt;/p&gt;
&lt;h2 id=&#34;329&#34;&gt;3.29&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/max-consecutive-ones-iii/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1004.最大连续1的个数 III&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/maximize-the-confusion-of-an-exam/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2024.考试的最大困扰度&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;两道一样的滑动窗口&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/checking-existence-of-edge-length-limited-paths/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1697.检查边长度限制的路径是否存在&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;第一次理解 &lt;code&gt;离线&lt;/code&gt; 和 &lt;code&gt;在线&lt;/code&gt; 的说法&lt;/p&gt;
&lt;p&gt;很巧妙的根据dis和limit排序&lt;/p&gt;
&lt;p&gt;保证dis &amp;lt; limit的情况下只需要用uf判断连通性即可&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/count-submatrices-with-all-ones/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1504. 统计全 1 子矩形&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;枚举理解了&lt;/p&gt;
&lt;p&gt;单调栈不是很懂&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/count-square-submatrices-with-all-ones/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1277. 统计全为 1 的正方形子矩阵&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这题虽然跟上题很像，但是可以dp，简单很多&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/largest-submatrix-with-rearrangements/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1727. 重新排列后的最大子矩阵&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看上去跟前面两题很像，但思路其实感觉是84/85的思路&lt;/p&gt;
&lt;p&gt;预处理算包括当前位置在内的上方连续的1，然后对每一行排序，遍历，顺便剪枝优化&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/groups-of-strings/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2157. 字符串分组&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一眼就能看出是并查集&lt;/p&gt;
&lt;p&gt;但是比较难想到是二进制枚举，以及替换一个字母的表示&lt;/p&gt;
&lt;p&gt;有一些细节没想明白&lt;/p&gt;
&lt;h2 id=&#34;330&#34;&gt;3.30&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/find-servers-that-handled-most-number-of-requests/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1606. 找到处理最多请求的服务器&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;几乎没有思路，最后只能想到可能用优先队列，然后还是不知道怎么做&lt;/p&gt;
&lt;p&gt;维护两个pq，分别根据编号维护空闲服务器，根据结束时间维护工作中服务器&lt;/p&gt;
&lt;p&gt;很巧妙的用了 &lt;code&gt;i + (idx - i) % k&lt;/code&gt; 入队，并且这里还用到了python负数取模变成同余的非负数的性质，&lt;/p&gt;
&lt;p&gt;别的语言应该是 &lt;code&gt;i + ((idx - i) % k + k) % k&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;目的其实都是一样的，保证得到的是一个不小于 i 的且与 id 同余的数，从而能够保证当前轮次以及下一轮次能够按照服务器编号顺序接受请求&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/network-delay-time/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;743. 网络延迟时间&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比较经典的Dijkstra&lt;/p&gt;
&lt;p&gt;矩阵枚举和优先队列两种写法&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/minimum-cost-to-make-at-least-one-valid-path-in-a-grid/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1368. 使网格图至少有一条有效路径的最小代价&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;虽然知道要用Dijkstra但是读完题根本想不到，看完题解才明白&lt;/p&gt;
&lt;p&gt;实际上就是顺着箭头的weight=0，变换方向weight=1&lt;/p&gt;
&lt;p&gt;明白这一点之后就是板子题了&lt;/p&gt;
&lt;p&gt;另外学习了一种 &lt;code&gt;0-1 广度优先搜索&lt;/code&gt; ，核心就是双端队列&lt;/p&gt;
&lt;p&gt;weight为0的从队首入队，为1从队尾入队&lt;/p&gt;
&lt;p&gt;这样就保证从原点开始的距离单调增&lt;/p&gt;
&lt;p&gt;（可以拓展到图中只有两种weighta, b，a!=b 的情况&lt;/p&gt;
&lt;p&gt;写法其实和dij类似&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/minimum-weighted-subgraph-with-the-required-paths/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2203. 得到要求路径的最小带权子图&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;周赛没写出来的题hhh&lt;/p&gt;
&lt;p&gt;主要是思路，能想到枚举相交点就很好解决了&lt;/p&gt;
&lt;p&gt;想到了就是板子题&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/path-with-maximum-probability/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1514. 概率最大的路径&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;权重变成概率&lt;/p&gt;
&lt;p&gt;dij板子题&lt;/p&gt;
&lt;p&gt;唯一有点坑就是python没有大顶堆，得用 &lt;code&gt;heappush(q, -elem)&lt;/code&gt; 和 &lt;code&gt;-heappop(q)&lt;/code&gt; 实现&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/number-of-ways-to-arrive-at-destination/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1976. 到达目的地的方案数&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一眼dij&lt;/p&gt;
&lt;p&gt;但是求方案数不太会，学习了一下&lt;/p&gt;
&lt;p&gt;求出最短路之后反推就行，记得用@cache优化&lt;/p&gt;
&lt;h2 id=&#34;331&#34;&gt;3.31&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/self-dividing-numbers/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;728. 自除数&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;暴力，没啥好说的&lt;/p&gt;
&lt;p&gt;第一次拿到每月打卡勋章hhh&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/number-of-restricted-paths-from-first-to-last-node/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1786. 从第一个节点出发到最后一个节点的受限路径数&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一开始题意没读懂，理解了半天&lt;/p&gt;
&lt;p&gt;dij，然后反推，跟1976很像，只是反推的条件不同&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/reachable-nodes-in-subdivided-graph/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;882. 细分图中的可到达结点&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;自己思考做出来了hard，很开心哈哈&lt;/p&gt;
&lt;p&gt;核心还是先dij算出最小距离（weight为cnt + 1），之后遍历边，根据边的两点分别判断，最后加上可达的点即可&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/cheapest-flights-within-k-stops/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;787. K 站中转内最便宜的航班&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;套完dij之后就不知道该怎么做了，主要是k的限制，看题解学习了一下&lt;/p&gt;
&lt;p&gt;dist[i] -&amp;gt; dist[i] [j] ，其实就是dp思想&lt;/p&gt;
&lt;p&gt;之后相应改一改dist就可以了&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/minimum-cost-to-reach-destination-in-time/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1928. 规定时间内到达终点的最小花费&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;跟787其实一样&lt;/p&gt;
&lt;p&gt;dist -&amp;gt; cost&lt;/p&gt;
&lt;p&gt;k -&amp;gt; max_time&lt;/p&gt;
&lt;p&gt;Dij + dp&lt;/p&gt;
&lt;h2 id=&#34;41&#34;&gt;4.1&lt;/h2&gt;
&lt;p&gt;Happy April Fool&amp;rsquo;s Day!&lt;/p&gt;
&lt;p&gt;晚上才开始刷题hhh&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/array-of-doubled-pairs/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;954. 二倍数对数组&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一开始想的排序+二分，另外维护一个记录，细节好像比较麻烦（其实是不会写二分&lt;/p&gt;
&lt;p&gt;后面想到了pq+dict，思路很清楚，但是由于python处理堆比较麻烦，写了40多行，还好一次ac&lt;/p&gt;
&lt;p&gt;看了一下题解，只能说方向是对的&lt;/p&gt;
&lt;p&gt;直接维护dict（用Counter，然后从绝对值小的开始判断即可&lt;/p&gt;
&lt;p&gt;看题解还可以用拓扑排序做，记个TODO，刷完dij来再做一次&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/maximum-compatibility-score-sum/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1947. 最大兼容性评分和&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;毫无思路，看了题解之后做的，做完还是不知道tag里的dij哪来的&lt;/p&gt;
&lt;p&gt;先预处理出每个学生对应每个老师的得分，&lt;/p&gt;
&lt;p&gt;之后由于数据量不大，想到二进制枚举，0/1代表当前老师是否已经被选，&lt;/p&gt;
&lt;p&gt;接着需要记录状态转移，即当前枚举bit下最大得分，所以用了dp数组，&lt;/p&gt;
&lt;p&gt;而且需要当前位为1才能进状态转移，因为是根据这个位不为1的状态进行转移的&lt;/p&gt;
&lt;p&gt;有个比较tricky的地方，转移的时候要知道当前学生编号为c-1，其实就是因为已经当前已经有c-1个导师被选中了，学生和导师是一一对应的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/minimum-xor-sum-of-two-arrays/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1879. 两个数组最小的异或值之和&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;和1947几乎完全一样，唯一不同是dp数组初始化，以及需要注意base case&lt;/p&gt;
&lt;p&gt;预处理+ 二进制枚举+dp&lt;/p&gt;
&lt;h2 id=&#34;42&#34;&gt;4.2&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/strong-password-checker/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;420. 强密码检验器&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;模拟，想不出来，就看答案了&lt;/p&gt;
&lt;p&gt;看了还是不太会hhh，先放一放吧&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/swim-in-rising-water/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;778. 水位上升的泳池中游泳&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一开始看到tag，往dij方向想，没想出来&lt;/p&gt;
&lt;p&gt;看到题解后用bfs+pq很简单做出来&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/min-cost-to-connect-all-points/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1584. 连接所有点的最小费用&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;mst板子题&lt;/p&gt;
&lt;p&gt;用kruskal怎么写都不对，一开始发现边没从j+1开始造，改了发现还是不对，麻了&lt;/p&gt;
&lt;p&gt;prim过了&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/trapping-rain-water-ii/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;407. 接雨水 II&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一开始的思路是模仿二维的，维护四个方向的最小值，取最小值减，但是没有想具体实现，感觉比较麻烦&lt;/p&gt;
&lt;p&gt;其实思路是对的，实现用最小堆+visited&lt;/p&gt;
&lt;p&gt;首先边上一圈肯定接不到雨水，预处理，记录已经visit并且入堆，&lt;/p&gt;
&lt;p&gt;之后循环取堆中最小的进行四周遍历，能填就往里填，再入堆（注意入堆的是接过雨水之后的高度，可能不变也可能变高&lt;/p&gt;
&lt;p&gt;双周赛a3道，最后一题拓展KMP板子，不会&lt;/p&gt;
&lt;h2 id=&#34;43&#34;&gt;4.3&lt;/h2&gt;
&lt;p&gt;周赛第一次AKhhh&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/find-smallest-letter-greater-than-target/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;744. 寻找比目标字母大的最小字母&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;模拟就行，还可以二分&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/course-schedule-ii/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;210. 课程表 II&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;和207类似，拓扑排序，顺便记录一下就行&lt;/p&gt;
&lt;p&gt;拓扑排序其实就是维护入度+bfs&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/find-eventual-safe-states/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;802. 找到最终的安全状态&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;建立反图再拓扑排序即可&lt;/p&gt;
&lt;p&gt;看题解学习了dfs+三色标记，维护一个记录节点颜色数组，分别代表状态为未访问，正在访问的栈中/在环上，已访问过且不在环上，&lt;/p&gt;
&lt;p&gt;对每个点进行dfs即可&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/minimum-height-trees/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;310. 最小高度树&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一开始想的统计度，最小的作为根节点，发现不太行&lt;/p&gt;
&lt;p&gt;看了题解，其实思路差不多，也是拓扑排序bfs的板子&lt;/p&gt;
&lt;p&gt;维护degree表，双向的图，用队列bfs，度为1的入队&lt;/p&gt;
&lt;p&gt;其实最后只可能剩下1/2个可能的根节点&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/sort-items-by-groups-respecting-dependencies/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1203. 项目管理&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;除了拓扑没什么思路，无从下手&lt;/p&gt;
&lt;p&gt;看了题解，思路真的牛逼&lt;/p&gt;
&lt;p&gt;双重拓扑排序，先根据组的关系排一次，得到组的顺序，再根据每一组内的项目进行排序&lt;/p&gt;
&lt;p&gt;有几个比较tricky的地方：一是没有组的需要改成不同的组号，维护变量遍历改即可，&lt;/p&gt;
&lt;p&gt;二是需要注意在不同组的时候，需要根据项目建图，而不是根据组建图，vice versa&lt;/p&gt;
&lt;p&gt;其间任何一次拓扑排序后结果不正确（有环，都可以直接return空&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/course-schedule-iv/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1462. 课程表 IV&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;板子题，另外维护一个前置节点即可&lt;/p&gt;
&lt;p&gt;注意python的set取交集用 |&lt;/p&gt;
&lt;p&gt;看题解发现了用dfs + @cache，不得不说python的@cache真的赖皮&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/strange-printer-ii/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1591. 奇怪的打印机 II&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;完全没有思路&lt;/p&gt;
&lt;p&gt;看了答案才知道为什么用拓扑排序&lt;/p&gt;
&lt;p&gt;对每种颜色进行遍历，确定最大范围，在这个颜色范围内，不是这个颜色，说明在涂完这个颜色后，又新涂了当前颜色，&lt;/p&gt;
&lt;p&gt;所以可以理解为一种先后关系，原来的颜色 -&amp;gt; 现在的颜色，所以可以建图，维护入度&lt;/p&gt;
&lt;p&gt;题目中限定数字范围为&amp;lt;=60，所以开61的空间就好&lt;/p&gt;
&lt;p&gt;之后就是板子题了&lt;/p&gt;
&lt;p&gt;犯了个很sb的错误，找了半天bug，心态崩了&lt;/p&gt;
&lt;h2 id=&#34;44&#34;&gt;4.4&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/range-sum-query-mutable/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;307. 区域和检索 - 数组可修改&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;树状数组/线段树 板子题&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/rank-transform-of-a-matrix/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1632. 矩阵转换后的秩&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;真困难题&lt;/p&gt;
&lt;p&gt;因为只考虑每行/列的相对关系，所以可以用拓扑排序&lt;/p&gt;
&lt;p&gt;但是写到最后出了点问题，因为当行/列元素相同时需要保证该元素的最终值为相等元素的值中最大的那一个，想了一下只能想到并查集，感觉很麻烦，就看答案了&lt;/p&gt;
&lt;p&gt;结果一看真是并查集&lt;/p&gt;
&lt;p&gt;不想改了，cv&lt;/p&gt;
&lt;p&gt;（看了一下是codeforces div1的c题原题&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/largest-color-value-in-a-directed-graph/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1857. 有向图中最大颜色值&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;困难的点在于记录颜色值，没什么思路&lt;/p&gt;
&lt;p&gt;看了答案，其实开个数组记录就可以了（或者说是dp&lt;/p&gt;
&lt;p&gt;dp[i] [j]：到i点为止，颜色j的最大值，然后在拓扑排序的过程中更新状态即可&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/parallel-courses-iii/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2050. 并行课程 III&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;跟1857很像，拓扑+dp维护所需最大时间即可&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/find-all-possible-recipes-from-given-supplies/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2115. 从给定原材料中找到所有可以做出的菜&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;很早之前周赛的一道题目，当时还不怎么会写拓扑排序hhh&lt;/p&gt;
&lt;p&gt;思路很简单，但是比较坑的一点就是ingredients里面可能在recipes和supplies都没出现过，我的处理是只加入度不加边&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/groups-of-strings/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2157. 字符串分组&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;真困难题&lt;/p&gt;
&lt;p&gt;3.29做过的题，当时没做完，又做了一下，应该是之前做过几道二进制枚举题目的原因，完全理解了解题思路&lt;/p&gt;
&lt;p&gt;由于 &lt;code&gt;只考虑s1和s2的集合&lt;/code&gt; ，也就是说出现顺序无关，并且每个字母最多出现一次，所以可以用二进制位表示，&lt;/p&gt;
&lt;p&gt;为了得到答案的分组数和最大个数，需要用 &lt;code&gt;并查集&lt;/code&gt; ，&lt;/p&gt;
&lt;p&gt;那么删除/添加一个字母，分别对应异或当前位，由1变0和由0变1，&lt;/p&gt;
&lt;p&gt;替换一个字母，实际上是删除一个字母，然后再次遍历，并且只能是添加一个字母，&lt;/p&gt;
&lt;p&gt;其中可以维护一个set来快速判断是否存在于word，以及record记录words中对应的并查集parent&lt;/p&gt;
&lt;p&gt;最后9秒多过了，差点TLE了，看来评论说python卡常是真的&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/maximum-employees-to-be-invited-to-a-meeting/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2127. 参加会议的最多员工数&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;真困难题&lt;/p&gt;
&lt;p&gt;pending一下，不太会&lt;/p&gt;
&lt;p&gt;题解说是内向基环树&lt;/p&gt;
&lt;p&gt;看了群主的视频，思路很清晰了，主要是分析部分：&lt;/p&gt;
&lt;p&gt;分析可得，对于图的每一个连通部分，有两种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;有环，且环上的点个数 &amp;gt;= 3&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有环，且环上的点个数 == 2&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于情况1，最大满足条件的个数只能为环上的个数，因为此时每个点的两边都已经定了&lt;/p&gt;
&lt;p&gt;对于情况2，此时图的形状是两元环+每个顶点延伸的边，&lt;/p&gt;
&lt;p&gt;此时最大满足条件个数可以加上其他连通部分的情况2下的点数总和，&lt;/p&gt;
&lt;p&gt;因为对于情况2中的顶点，无论是二元环上的点还是延伸边上的点，都还有另一边空着，&lt;/p&gt;
&lt;p&gt;所以拓扑排序时，为每个点维护变量记录向外延展的个数，&lt;/p&gt;
&lt;p&gt;维护一个visited数组，排序完后visited[i] = False为环上点，再对每一个连通分量进行遍历，择优&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/jC7MId/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;剑指 Offer II 051. 节点之和最大的路径&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;做过的题还是不会做&lt;/p&gt;
&lt;p&gt;果然纯靠理解做和靠刷题堆砌的结果还是有差距的，说到底还是我太菜了&lt;/p&gt;
&lt;p&gt;后序遍历就可以了，注意更新res的值和返回的值不一样，更新的值可以是l+r+root.val，因为在同一条路径上，但返回只能返回最大值了&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/NYBBNL/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;剑指 Offer II 052. 展平二叉搜索树&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;主要是一开始用一个dummy，然后维护一个pre&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/P5rCT8/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;剑指 Offer II 053. 二叉搜索树中的中序后继&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;利用好二叉搜索树性质中序遍历就可以了&lt;/p&gt;
&lt;p&gt;应该是简单题。。&lt;/p&gt;
&lt;h2 id=&#34;45&#34;&gt;4.5&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/prime-number-of-set-bits-in-binary-representation/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;762. 二进制表示中质数个计算置位&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;暴力就行&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/lexicographically-smallest-string-after-applying-operations/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1625. 执行操作后字典序最小的字符串&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;以为有什么厉害的解法，结果居然就是枚举&lt;/p&gt;
&lt;p&gt;先累加遍历，再轮转遍历（反过来也行，然后取最小&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/number-of-subarrays-with-bounded-maximum/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;795. 区间子数组个数&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;题解的思路很精妙：&lt;/p&gt;
&lt;p&gt;小于等于right的子数组数 - 小于等于left - 1的子数组数 = [left, right]的子数组数，&lt;/p&gt;
&lt;p&gt;所以写个count函数计算小于等于k的子数组数就可以了&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/change-minimum-characters-to-satisfy-one-of-three-conditions/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;1737. 满足三条件之一需改变的最少字符数&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;太菜了，根本没思路，答案思路：&lt;/p&gt;
&lt;p&gt;分别统计ab中每个字母出现次数，然后对i进行枚举，使得a中每个字母都小于等于i，b中每个字母都大于i，&lt;/p&gt;
&lt;p&gt;这样分别对应情况1和2，&lt;/p&gt;
&lt;p&gt;有个tricky的点，枚举中a是可以的，但z不行，因为字母不能大于z，&lt;/p&gt;
&lt;p&gt;情况3通过枚举i，使得a，b每个字母都为i，需要的操作数也就是ab的长度和减去i在ab中分别出现的次数，&lt;/p&gt;
&lt;p&gt;最后择优即可&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/detect-squares/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;2013. 检测正方形&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;用counter或者hashmap记录一下，每次枚举遍历就可了&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://leetcode-cn.com/problems/search-insert-position/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;35. 搜索插入位置&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;二分，水一题hhh&lt;/p&gt;
&lt;p&gt;&amp;ndash;600啦，暂时不想刷了hh&amp;ndash;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Cuckoo Filter</title>
        <link>https://example.com/p/cuckoo-filter/</link>
        <pubDate>Fri, 25 Mar 2022 22:19:50 +0800</pubDate>
        
        <guid>https://example.com/p/cuckoo-filter/</guid>
        <description>&lt;p&gt;&lt;em&gt;前言&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;逛GitHub的时候看到了&lt;a class=&#34;link&#34; href=&#34;https://github.com/CDDSCLab/training-plan&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;这个repo&lt;/a&gt;，里面提到了Cuckoo Filter，没听说过，学习一下，顺便做个笔记持久化。&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;
&lt;p&gt;实际上源于2014年CMU的一篇论文：&lt;a class=&#34;link&#34; href=&#34;https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Cuckoo Filter: Practically Better Than Bloom&lt;/a&gt;，听名字就知道，和布隆过滤器类似。&lt;/p&gt;
&lt;h3 id=&#34;什么是cuckoo-filter&#34;&gt;什么是Cuckoo Filter&lt;/h3&gt;
&lt;p&gt;论文摘要：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In many networking systems, Bloom filters are used for highspeed set membership tests. They permit a small fraction of false positive answers with very good space efficiency. However, &lt;strong&gt;they do not permit deletion of items from the set&lt;/strong&gt;, and previous attempts to extend “standard” Bloom filters to support deletion all &lt;strong&gt;degrade either space or performance&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We propose a new data structure called the &lt;strong&gt;cuckoo filter&lt;/strong&gt; that can replace Bloom filters for approximate set membership tests. Cuckoo filters &lt;strong&gt;support adding and removing items dynamically while achieving even higher performance&lt;/strong&gt; than Bloom filters. For applications that store many items and target moderately low false positive rates, cuckoo filters have lower space overhead than space-optimized Bloom filters. Our experimental results also show that cuckoo filters outperform previous data structures that extend Bloom filters to support deletions substantially in both time and space.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简单来说就是解决了Bloom Filter不能删除，或者删除影响空间或时间上的性能的问题。Cuckoo Filter在解决这一问题的同时，还能够表现出更好的性能。（吹是这么吹的）&lt;/p&gt;
&lt;p&gt;在合适的参数配置下，空间利用率可以达到95%。&lt;/p&gt;
&lt;h3 id=&#34;为什么叫cuckoo-filter&#34;&gt;为什么叫Cuckoo Filter&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Cuckoo&lt;/code&gt; 的意思是 &lt;code&gt;布谷鸟&lt;/code&gt; ，取这个名字其实跟他的算法实现有关。&lt;/p&gt;
&lt;p&gt;看一张论文里的图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/cuckoo_hashing.png&#34;
	width=&#34;1558&#34;
	height=&#34;606&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/cuckoo_hashing_hu47387e887ccc95c3501cbfc7667701db_124475_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/cuckoo_hashing_hu47387e887ccc95c3501cbfc7667701db_124475_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Cuckoo Hashing&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;257&#34;
		data-flex-basis=&#34;617px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看到每个item会有两个 &lt;code&gt;candidate buckets&lt;/code&gt; ，如果有任意一个是空的，直接插入即可；如果都已经被占了，则会&lt;strong&gt;任意&lt;/strong&gt;挑选出一个bucket，把其中的元素移出来，再将这个 &lt;code&gt;victim&lt;/code&gt; 插入到其他可供选择的地方。&lt;/p&gt;
&lt;p&gt;这个过程会一直重复到能找到一个空的bucket，或者替换次数达到一个阈值（原文为500次）。&lt;/p&gt;
&lt;p&gt;尽管Cuckoo Hashing可能会引起一系列的替换，但是这个操作的均摊时间复杂度是O(1)。&lt;/p&gt;
&lt;p&gt;回到名字上来，这个过程其实和布谷鸟下蛋很像。&lt;/p&gt;
&lt;p&gt;布谷鸟会把蛋下到别的鸟的巢里，而布谷鸟的幼鸟比别的鸟出生的早，于是会将别的还没出生的鸟蛋挤出巢外，来保证自己今后能独享食物。&lt;/p&gt;
&lt;p&gt;懂了之后就会感觉这个命名确实很生动，也让人不禁想到Kafka中一系列有趣的命名。计算机科学家还是很有意思的。&lt;/p&gt;
&lt;p&gt;另外，(c) 图中展示的是优化过后的hash table，可以看到一个bucket中有4个entry，很大程度上减少了冲突几率。&lt;/p&gt;
&lt;h2 id=&#34;优化&#34;&gt;优化&lt;/h2&gt;
&lt;p&gt;如果只根据标准的Cuckoo hashing方法计算冲突时可选的空间，（原文中说）一个很容易想到的方法是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;store each inserted item in its entirety (perhaps externally to the table); given the original item (“key”), calculating its alternate location is easy&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我的理解就是，对于每一个插入的item，都维护一个变量（可以看作是这个item的entirety），这个变量记录了这个item所有可能的index值，然后再对key进行计算。重点在于维护这个变量需要的在hash table之外的&lt;strong&gt;额外空间&lt;/strong&gt;，会产生比较大的开销。&lt;/p&gt;
&lt;p&gt;为了达到更好的空间上的效率，减少hash table以外的大小，提出了下面的优化。&lt;/p&gt;
&lt;h3 id=&#34;partial-key-cuckoo-hashing&#34;&gt;partial-key cuckoo hashing&lt;/h3&gt;
&lt;p&gt;每一个item都根据一个常数大小的 &lt;code&gt;fingerprint&lt;/code&gt; 进行hash。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为什么这个fingerprint也需要额外空间，刚才的entirety也需要额外空间，就算成优化了呢？其实很简单，因为fingerprint相较于entirety需要的空间开销更小，是常数级别的。并且在后面可以看到，对于大部分数据，4~5bit大小的fingerprint就能够达到非常好的空间占用率。而如果采用entirety，在下面的算法实现中可以看到，对于每一个bucket计算出备选bucket的index时，还需要回溯(retrieve)出该bucket的值，而采用fingerprint就可以避免这一操作。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;算法实现&#34;&gt;算法实现&lt;/h2&gt;
&lt;p&gt;主要是三部分：插入、查询和删除。&lt;/p&gt;
&lt;h3 id=&#34;插入&#34;&gt;插入&lt;/h3&gt;
&lt;p&gt;先看下原文的伪代码实现：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/insert.png&#34;
	width=&#34;1036&#34;
	height=&#34;936&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/insert_huafcab5030055f94c3e47a71edb150854_143137_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/insert_huafcab5030055f94c3e47a71edb150854_143137_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;insert-伪代码&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;110&#34;
		data-flex-basis=&#34;265px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;需要注意的是，计算i2的时候用到了i1和hash(f)的异或，这是很方便也很有必要的，因为这样一来，就可以保证i1也可以用同样的方式通过i2和hash(f)计算得出。所以，当我们需要计算出当前bucket的备选bucket时，只需要根据当前bucket的下标i以及存在bucket中的fingerprint得到备选目标j，即：&lt;/p&gt;
&lt;p&gt;$$j = i\oplus hash(fingerprint)$$&lt;/p&gt;
&lt;p&gt;这样一来，每次插入实际上只用到了表内的信息，不需要追溯到原来的item。&lt;/p&gt;
&lt;p&gt;并且可以看到，在每次异或运算前对fingerprint进行hash而不是之后，目的也是为了减少冲突，否则如果先异或后hash，很容易落到临近的bucket中。&lt;/p&gt;
&lt;p&gt;此外，如果两个或多个item具有相同的fingerprint，也是可以的，但有一个上限 &lt;code&gt;2b&lt;/code&gt; ，b为bucket的大小，此时这些重复的item的两个bucket将会变得超载。&lt;/p&gt;
&lt;p&gt;循环中 &lt;code&gt;MaxNumKicks&lt;/code&gt; 其实就是最大重试次数，比如500次，如果超过这个次数还没有成功插入，就可以认为这个table满了。&lt;/p&gt;
&lt;p&gt;并且也可以看到，通过 &lt;code&gt;partial-key&lt;/code&gt; 的优化，现在每次冲突时计算备选空间地址，无论冲突了多少次，只需要根据fingerprint，还是很方便的。&lt;/p&gt;
&lt;h3 id=&#34;查询&#34;&gt;查询&lt;/h3&gt;
&lt;p&gt;伪代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/lookup.png&#34;
	width=&#34;1022&#34;
	height=&#34;414&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/lookup_hu60cb88140d1a98b7e3a322bbbbd5fd53_52523_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/lookup_hu60cb88140d1a98b7e3a322bbbbd5fd53_52523_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;lookup-伪代码&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;246&#34;
		data-flex-basis=&#34;592px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;删除&#34;&gt;删除&lt;/h3&gt;
&lt;p&gt;伪代码：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/delete.png&#34;
	width=&#34;1024&#34;
	height=&#34;446&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/delete_hu071bd94d923ff16b665f3e678e2917cd_60911_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/delete_hu071bd94d923ff16b665f3e678e2917cd_60911_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;delete-伪代码&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;229&#34;
		data-flex-basis=&#34;551px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;删除操作思路很简单，判断一下两个桶有没有相符的fingerprint，有就删除。这里的删除也不是真的把数据删除，而只是简单的标记一下。&lt;/p&gt;
&lt;h2 id=&#34;效果&#34;&gt;效果&lt;/h2&gt;
&lt;p&gt;简单的看下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/cuckoo-filter/load-factor.png&#34;
	width=&#34;2214&#34;
	height=&#34;1012&#34;
	srcset=&#34;https://example.com/p/cuckoo-filter/load-factor_hu492471baf84afe3062376e79d1ee2c7b_315168_480x0_resize_box_3.png 480w, https://example.com/p/cuckoo-filter/load-factor_hu492471baf84afe3062376e79d1ee2c7b_315168_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;bucket size为4和8情况下 load factor和fingerprint size关系图&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;218&#34;
		data-flex-basis=&#34;525px&#34;
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;这里就援引论文中的Conclusion：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Cuckoo filters are a new data structure for approximate set membership queries that can be used for many networking problems formerly solved using Bloom filters. Cuckoo filters improve upon Bloom filters in three ways: (1) &lt;strong&gt;support for deleting items dynamically&lt;/strong&gt;; (2) &lt;strong&gt;better lookup performance&lt;/strong&gt;; and (3) &lt;strong&gt;better space efficiency for applications requiring low false positive rates&lt;/strong&gt; (&amp;lt; 3%). A cuckoo filter stores the fingerprints of a set of items based on cuckoo hashing, thus achieving high space occupancy. As a further key contribution, we have applied &lt;strong&gt;partial-key&lt;/strong&gt; cuckoo hashing, which makes cuckoo filters significantly more efficient by allowing relocation based on &lt;strong&gt;only the stored fingerprint&lt;/strong&gt;. Our configuration exploration suggests that the cuckoo filter, which uses buckets of size 4, will perform well for a wide range of applications, although appealingly cuckoo filter parameters can be easily varied for application-dependent tuning.&lt;/p&gt;
&lt;p&gt;While we expect that further extensions and optimizations to cuckoo filters are possible and will further provide impetus for their use, the data structure as described is a fast and efficient building block already well-suited to the practical demands of networking and distributed systems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;几个重点也都加粗了，主要是相比于Bloom Filter的三大优势：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;支持动态删除&lt;/li&gt;
&lt;li&gt;查询性能更好&lt;/li&gt;
&lt;li&gt;空间效率更高&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;并且经过 &lt;code&gt;partial-key&lt;/code&gt; 的优化，对于每一个item，只需要额外存储 &lt;code&gt;fingerprint&lt;/code&gt; 的值作为hash的依据，节省空间开销。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>《凤凰架构》读书笔记（1）</title>
        <link>https://example.com/p/fenix_arch_book_1/</link>
        <pubDate>Fri, 11 Mar 2022 15:07:15 +0800</pubDate>
        
        <guid>https://example.com/p/fenix_arch_book_1/</guid>
        <description>&lt;h2 id=&#34;第1章-服务架构演进史&#34;&gt;第1章 服务架构演进史&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;架构并不是被发明出来的，而是持续演进的结果&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;2 Pizza Team&lt;/code&gt;: 衡量团队大小的量词，指两个Pizza能喂饱的人数，挺有意思&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;单体系统的真正缺陷不在如何拆分，而在&lt;strong&gt;拆分之后的自治与隔离能力&lt;/strong&gt;上。由于所有代码都运行在同一个进程内，所有模块、方法的调用都无须考虑&lt;strong&gt;网络分区&lt;/strong&gt;、&lt;strong&gt;对象复制&lt;/strong&gt;这些麻烦的事。&lt;/p&gt;
&lt;p&gt;但在获得进程内调用的简单和高效的同时，也意味着一部分代码出现了缺陷，将会过度消耗进程空间内的资源，造成的影响也会是全局性、难以隔离的，例如&lt;strong&gt;内存泄漏&lt;/strong&gt;、&lt;strong&gt;线程爆炸&lt;/strong&gt;、&lt;strong&gt;阻塞&lt;/strong&gt;、&lt;strong&gt;死循环&lt;/strong&gt;等问题。如果出现问题的是某些更高层次的公共资源，例如端口号和数据库连接池泄漏，还会影响整台机器，乃至集群中其他单体副本的正常工作。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;code&gt;SOA&lt;/code&gt;: Service-Oriented Architecture，面向服务架构，三种代表性的架构模式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;烟囱式架构（信息孤岛）&lt;/li&gt;
&lt;li&gt;微内核架构（插件式架构）&lt;/li&gt;
&lt;li&gt;事件驱动架构&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SOAP协议被边缘化的本质原因：&lt;strong&gt;过于严格的规范定义带来过度复杂性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;ndash;&amp;gt; ==我的理解==：和OSI7层模型很像，是一种很好的思想，但实际中用到的往往是简化版的，例如5层，TCP/IP协议簇的4层&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;微服务的概念：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言、不同的存储技术，运行在不同的进程之中。服务采用轻量级的通信机制和自动化的部署机制实现通信与运维。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“微服务时代充满着自由的气息，微服务时代充斥着迷茫的选择。”&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;服务网格&lt;/strong&gt;(Service Mesh)的&lt;strong&gt;边车代理模式&lt;/strong&gt;(Sidecar Proxy)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/fenix_arch_book_1/sidecar_proxy.png&#34;
	width=&#34;1622&#34;
	height=&#34;952&#34;
	srcset=&#34;https://example.com/p/fenix_arch_book_1/sidecar_proxy_hu099d5a05ea85ba71ecf5339ce342528d_363902_480x0_resize_box_3.png 480w, https://example.com/p/fenix_arch_book_1/sidecar_proxy_hu099d5a05ea85ba71ecf5339ce342528d_363902_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;边车代理&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;170&#34;
		data-flex-basis=&#34;408px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;在虚拟化场景中的边车指，由系统自动在服务容器（通常是k8s的pod）中注入一个&lt;strong&gt;通信代理服务器&lt;/strong&gt;，以类似中间人攻击的方式进行流量劫持，在应用无感知的情况下接管通信。&lt;/p&gt;
&lt;p&gt;这个代理除了实现正常的服务通信外（称为数据平面通信），还接收来自控制器的指令（控制平面通信），根据控制平面中的配置，对数据平面通信的内容进行分析处理，从而实现熔断、认证、度量、监控、负载均衡等各种附加功能。&lt;/p&gt;
&lt;p&gt;通过边车代理模式，既不需要在应用层加入额外的处理代码，也提供了几乎不亚于程序代码的精细管理能力。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Serverless的两大内容&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;后端设施&lt;/strong&gt;(Backend)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;指数据库、消息队列、日志、存储等这类用于支撑业务逻辑运行，但本身无业务含义的技术组件&lt;/p&gt;
&lt;p&gt;这些后端设施都运行在云中，在serverless中称为Baas(Backend as a Service)&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;&lt;strong&gt;函数&lt;/strong&gt;(Function)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;指业务逻辑代码，很接近程序编码角度的函数，区别在于serverless中的函数运行在云端，不必考虑算力和容量规划，称为FaaS(Function ..)&lt;/p&gt;
&lt;p&gt;无服务架构确实能降低一些应用的开发和运维成本，例如不需要交互的离线大规模计算，或者Web资讯类网站、小程序、公共API服务、移动应用服务端等契合于无服务架构所擅长的短链接、无状态、适合事件驱动的交互方式。&lt;/p&gt;
&lt;p&gt;但另一方面，对于诸如信息管理系统、网络游戏等，或说对具有业务逻辑复杂、依赖服务端状态、响应速度要求较高、需要长链接等特征的应用，至少目前不是那么合适。&lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;如果说微服务架构是分布式系统这条路当前所能做到的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;软件开发的最大挑战就在于只能在不完备的信息下决定当前要处理的问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;We can only see a short distance ahead, but we can see plenty there that needs to be done.&lt;/p&gt;
&lt;p&gt;&amp;ndash;Alan Turing&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        </item>
        <item>
        <title>NAT详解</title>
        <link>https://example.com/p/nat%E8%AF%A6%E8%A7%A3/</link>
        <pubDate>Sun, 06 Mar 2022 17:31:19 +0800</pubDate>
        
        <guid>https://example.com/p/nat%E8%AF%A6%E8%A7%A3/</guid>
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;还记得一个月前被面试官问到NAT的时候完全茫然，面试结束复盘的时候发现自己一直在用的内网穿透APP就是基于NAT的。平时还是得多问问为什么。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;在介绍NAT之前，首先需要简单介绍一下防火墙。&lt;/p&gt;
&lt;h2 id=&#34;防火墙&#34;&gt;&lt;strong&gt;防火墙&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;防火墙简介&#34;&gt;防火墙简介&lt;/h3&gt;
&lt;p&gt;防火墙的任务是&lt;strong&gt;控制互联网中网络流量的流向&lt;/strong&gt;，本质上是一种&lt;strong&gt;能够限制转发流量类型的路由器&lt;/strong&gt;。（代理防火墙严格意义上不算是）&lt;/p&gt;
&lt;p&gt;常见的防火墙主要有两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;包过滤防火墙（packet-filter firewall）&lt;/li&gt;
&lt;li&gt;代理防火墙（proxy firewall）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;包过滤防火墙是一个互联网路由器，能够根据条件对数据包进行丢弃/传输的操作。而代理防火墙是一个服务器主机，它作为TCP和UDP传输的一个端点，通常不会在IP协议层中路由IP数据包。&lt;/p&gt;
&lt;p&gt;二者的主要区别是&lt;strong&gt;所操作的协议栈的层次不同&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;包过滤防火墙&#34;&gt;包过滤防火墙&lt;/h3&gt;
&lt;p&gt;过滤器选项包括：IP地址、ICMP报文类型、数据包中的端口号等。&lt;/p&gt;
&lt;p&gt;包过滤防火墙可分为&lt;strong&gt;无状态的&lt;/strong&gt;和&lt;strong&gt;有状态的&lt;/strong&gt;。无状态的包过滤防火墙单独处理每一个数据包；而有状态的防火墙能够通过关联已经或者即将到达的数据包来推断数据信息。（举个例子，对于分片的IP报文，有状态的防火墙往往能够判断出其属于同一个IP数据报，但无状态的无法做到）&lt;/p&gt;
&lt;h3 id=&#34;代理防火墙&#34;&gt;代理防火墙&lt;/h3&gt;
&lt;p&gt;代理防火墙的本质是运行一个或多个应用层网关的主机。&lt;/p&gt;
&lt;p&gt;一般来说，防火墙内的客户端通常会进行特殊配制，从而能够连接到代理防火墙，而不是连接到真正提供服务的主机。所以说这种防火墙配置繁琐（必须为每个传输层服务设置一个代理，通过这个代理和新的服务器发起连接）。但也正因如此，代理防火墙是非常安全的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;我的理解中，这是一种用配置的繁琐换安全性的trade-off。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;常见的代理防火墙的形式有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP代理防火墙&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也称为Web代理，只能用于HTTP和HTTPS协议。这种代理对于内网用户来说相当于Web服务器，对于被访问的外部网站来说相当于Web客户端。&lt;/p&gt;
&lt;p&gt;此外，这种代理往往还提供其他的一些功能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Web缓存功能。对网页内容进行缓存，从而减少网页延迟，提高用户访问体验。（例如HTTP缓存）&lt;/li&gt;
&lt;li&gt;作为内容过滤器，基于黑名单屏蔽特定用户。&lt;/li&gt;
&lt;li&gt;隧道代理服务器，功能和2相反。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;SOCKS代理防火墙&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;相比于HTTP代理，范围更广，可以用于Web以外的其他服务。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;nat网络地址转换&#34;&gt;NAT网络地址转换&lt;/h2&gt;
&lt;h3 id=&#34;基本概念&#34;&gt;基本概念&lt;/h3&gt;
&lt;p&gt;书上关于NAT的基本概念这一块个人认为解释的非常清楚，直接拿来：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NAT(Network Address Translation)&lt;strong&gt;本质&lt;/strong&gt;上是一种允许在互联网不同地方重复使用相同的IP地址集的机制。建立NAT的&lt;strong&gt;主要动机&lt;/strong&gt;是正在急剧减少的有限IP地址空间。使用NAT&lt;strong&gt;最常见的情况&lt;/strong&gt;是，唯一与Internet连接的站点仅被分配了很少的几个IP地址（甚至只有一个IP地址），但是内部却有多台主机需要同时上网。当所有进出的流量均通过一个单独的NAT设备时，该设备将内部系统的地址空间和全球互联网地址空间分割开，因此所有的内部系统可以使用本地分配的私有IP地址访问互联网。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;NAT的工作原理是&lt;strong&gt;重写通过路由器数据包的识别信息&lt;/strong&gt;，并且大多数的NAT同时进行地址转换和包过滤。&lt;/p&gt;
&lt;p&gt;引入NAT其实一开始主要为了解决两个问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;IP地址不够用&lt;/li&gt;
&lt;li&gt;路由可扩展性不强&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中，&lt;strong&gt;CIDR&lt;/strong&gt;的发展比较好的解决了后一个问题。（书上是这么描述的，但我觉得这两个问题归根结底是一个问题。可能书上想表达的意思是，路由可扩展性不强，是由于5种IP地址种类已经定死了，无法再修改，而CIDR解决了这个问题；而IP地址不够用，是因为在IP地址定死了，不可变，我们不去考虑IP地址分类的前提条件下，一个IP只能对应一个地址，不能被复用）&lt;/p&gt;
&lt;p&gt;NAT也一定程度上缓解了前一个问题。但是NAT毕竟只是权宜之计，真正解决第一个问题还是得用IPv6，但是又因为NAT发展的太好了，使用的人太多了，反而拖延了IPv6的推进。&lt;/p&gt;
&lt;p&gt;对于NAT，也有很多其他的缺点，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果想要让NAT内部的主机能够被访问，必须进行特殊配置，因为互联网上的用户无法直接访问私有地址的主机&lt;/li&gt;
&lt;li&gt;为了让NAT正常工作，每一个属于同一个连接或者关联的双向数据包都必须通过相同的NAT，因为NAT必须重写每个数据包的寻址信息，从而双方正常通信。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;传统nat基本nat和napt&#34;&gt;传统NAT：基本NAT和NAPT&lt;/h3&gt;
&lt;p&gt;传统的基本的NAT只执行对IP地址的重写，实际上这种NAT没什么用，因为需要的还是相同数量的IP地址。一个更好的做法是NAPT，NAPT使用传输层标识符（也就是TCP和UDP的端口）来确定一个特定的数据包到底和NAT内部的哪台私有主机关联。这样一来只需要很少的公有地址就可以让大量的内部主机访问公网。&lt;/p&gt;
&lt;p&gt;需要注意的一点是，如果私有范围使用的全局地址空间和另一个互联网上的实体冲突时，请求可能无法到达该地址，因为采用相同地址的本地系统会屏蔽掉使用相同地址的远端系统。为了避免这种情况发生，RFC1918中保留了3个IPv4的地址，专门做为私有地址范围：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;10.0.0.0/8&lt;/li&gt;
&lt;li&gt;172.16.0.0/12&lt;/li&gt;
&lt;li&gt;192.168.0.0/16&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;也就是说，不会有以以上三个地址作为公网地址出现。&lt;/p&gt;
&lt;p&gt;对于NAPT，又可分为两种：&lt;/p&gt;
&lt;h4 id=&#34;对称型nat-symmetric&#34;&gt;对称型NAT (Symmetric)&lt;/h4&gt;
&lt;p&gt;对每个外部主机或端口的会话都会映射为不同的端口。&lt;/p&gt;
&lt;h4 id=&#34;圆锥型natcone&#34;&gt;圆锥型NAT(Cone)&lt;/h4&gt;
&lt;p&gt;圆锥型NAT又可细分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;完全圆锥型NAT(Full Cone)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;IP和端口都不受限&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;地址限制圆锥型(Address Restricted Cone)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;IP受限，端口不受限&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;端口限制圆锥型(Port Restricted Cone)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;端口限，IP不受限&lt;/p&gt;
&lt;h3 id=&#34;发夹和nat环回&#34;&gt;发夹和NAT环回&lt;/h3&gt;
&lt;p&gt;对于这个问题，书上是这样描述的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;假设主机X1试图建立一个到主机X2的连接。如果X1知道私有地址信息，X2:x2，这没有任何问题，因为可以直接进行连接。然而，在某些情况下X1只知道公用地址信息，X2&#39;:x2&#39;。在这些情况下，X1借助NAT采用目的地址X2&#39;:x2&amp;rsquo;尝试连接X2。当NAT意识到X2&#39;:x2&amp;rsquo;和X2:x2之间存在映射，并将数据包转发到位于NAT私有地址空间内的X2:x2时，会触发发夹过程。此时会出现一个问题，目的是X2:x2的数据报头部中的源地址应该是X1:x1还是X1&#39;:x1&#39;？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实问题就一句话：&lt;strong&gt;在只知道公用地址的前提下，对于内网中的数据包发送的源地址应该用内网地址还是公网地址？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果NAT给X2的数据包的源地址信息是X1&#39;:x1&#39;，即公有地址，那么这种NAT被称为有“外部源ID地址和端口”的发夹行为。之所以需要这种行为，是为了均采用全局路由地址的应用能够识别对方。（我的理解是，这相当于给内网地址披了一层皮，因为X2的逻辑可能是处理外网地址的请求，这样以来实现了&lt;strong&gt;规格化&lt;/strong&gt;。有点类似于&lt;strong&gt;IP隧道技术&lt;/strong&gt;。）&lt;/p&gt;
&lt;p&gt;还有一个比较有意思的地方是，为什么这种行为叫做**发夹(hairpinning)**呢？一开始没理解，于是上网搜了一下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/nat%E8%AF%A6%E8%A7%A3/hairpin.png&#34;
	width=&#34;1602&#34;
	height=&#34;532&#34;
	srcset=&#34;https://example.com/p/nat%E8%AF%A6%E8%A7%A3/hairpin_hu8aea337501150dec4cb4eb45a6fc1d8e_215067_480x0_resize_box_3.png 480w, https://example.com/p/nat%E8%AF%A6%E8%A7%A3/hairpin_hu8aea337501150dec4cb4eb45a6fc1d8e_215067_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;Hairpin&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;301&#34;
		data-flex-basis=&#34;722px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;看完这个解释，再结合具体的例子，hairpinning这个名字起的还真挺形象的。&lt;/p&gt;
&lt;h3 id=&#34;nat穿越&#34;&gt;NAT穿越&lt;/h3&gt;
&lt;p&gt;为了解决外网无法主动向内网建立连接的问题，主要通过&lt;strong&gt;NAT转换表&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在NAT内侧主机上运行的应用先发送一个虚拟的网络包给NAT外侧，而NAT不知道这个包内容究竟是什么，会正常读取包首部信息，并生成一个转换表。这时，如果转换表构造合理，NAT外侧的主机就可以和内侧主机建立连接并通信。&lt;/p&gt;
&lt;p&gt;比较常见的会话穿越技术有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;STUN(Session Traversal Utilities for NAT)，能够在多种环境中确定在NAT中使用的外部IP地址和端口号，也可以通过保持激活的信息来维持当前的NAT绑定。&lt;/li&gt;
&lt;li&gt;TURN(Traversal Using Relays around NAT)，将所有的数据交换都经由服务器来完成，这样NAT将没有障碍，但会造成服务器的负载、丢包、延迟问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;包过滤防火墙和nat&#34;&gt;包过滤防火墙和NAT&lt;/h2&gt;
&lt;h3 id=&#34;包过滤防火墙配置规则&#34;&gt;包过滤防火墙配置规则&lt;/h3&gt;
&lt;p&gt;对于包过滤防火墙，需要配置一套说明匹配条件的指令。其中每个规则通常包含模式匹配条件(pattern-matching criteria)和对应的动作(action)（很像Gateway里面的&lt;strong&gt;断言&lt;/strong&gt;），匹配条件通常是包字段值，例如源/目的IP地址、端口号等。&lt;/p&gt;
&lt;p&gt;当一个数据包到达时，就会在&lt;strong&gt;ACL&lt;/strong&gt;中按照顺序匹配条件，第一个匹配的规则执行相应的动作。比较常见的动作有阻止或加速相应流量、调整计数器、写入日志等**（AOP思想）**。&lt;/p&gt;
&lt;h3 id=&#34;iptables&#34;&gt;iptables&lt;/h3&gt;
&lt;p&gt;iptables是Linux中用来构建防火墙系统的，它能够提供无状态和有状态的包过滤，以及支持NAT和NAPT。&lt;/p&gt;
&lt;p&gt;iptables包含&lt;strong&gt;过滤表格(table)&lt;strong&gt;和&lt;/strong&gt;过滤链(chain)&lt;/strong&gt;，一个表格包括多个预定义的链，或者多个自定义的链。iptables有三个预定义的表格：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;filter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用来处理基本的包过滤，包括INPUT、FORWARD和OUTPUT三条过滤链，分别对应于目的地是防火墙路由器本身运行程序的流量、路由时通过防火墙的流量、从该防火墙主机出发的流量。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;nat&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;包含了PREROUTING、OUTPUT和POSTROUTING三条过滤链。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mangle&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;包含了五条链，主要用于任意修改数据包。&lt;/p&gt;
&lt;p&gt;每条过滤链是一个规则列表，每条规则是匹配条件和对应的动作，包括：ACCEPT（转发）、DROP（丢弃）、QUEUE（将数据包交给程序处理）、RETURN（在之前出发的一条链中继续，即返还该包），以及其他自定义的动作。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;参考资料：&lt;/p&gt;
&lt;p&gt;《TCP/IP详解 卷1:协议》&lt;/p&gt;
&lt;p&gt;《图解TCP/IP》&lt;/p&gt;
</description>
        </item>
        <item>
        <title>全文索引详解（基于InnoDB引擎）</title>
        <link>https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/</link>
        <pubDate>Sun, 06 Mar 2022 17:20:33 +0800</pubDate>
        
        <guid>https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/</guid>
        <description>&lt;p&gt;&lt;em&gt;注：以下部分内容来自《MySQL技术内幕：InnoDB存储引擎》，以及我个人的一些理解和引申。如有侵权，请联系我删除，谢谢！&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;为什么需要全文索引&#34;&gt;&lt;strong&gt;为什么需要全文索引&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;我们都知道，InnoDB中主要使用B+树作为索引（以及少量的哈希索引，主要是&lt;strong&gt;自适应哈希&lt;/strong&gt;）。根据B+树的特点，我们可以在有索引的情况下，使用索引的前缀进行查找，例如，检索以“Covid”作为标题开头的疫情新闻：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LIKE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Covid%&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这是可以实现的。（注意，这里和索引的&lt;strong&gt;最左匹配原则&lt;/strong&gt;没有关系。由于LIKE关键字，这里使用的是范围查询，而最左匹配原则在遇到范围查询时无效。）&lt;/p&gt;
&lt;p&gt;然而当我们需要将查询的关键字不在字段的开头（更多情况下的确是这样），那么我们的B+树索引就无法奏效了，例如，检索标题包含“Covid”的疫情新闻：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LIKE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;%Covid%&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;那么这时，就需要全文索引了。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;全文索引&#34;&gt;全文索引&lt;/h2&gt;
&lt;h3 id=&#34;定义&#34;&gt;定义&lt;/h3&gt;
&lt;p&gt;书上是这样定义全文索引的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;全文索引（Full-Text Search）是将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术。它可以根据需要获得全文中有关章、节、段、句、词等信息，也可以进行各种分析和统计。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;讲的很清楚。&lt;/p&gt;
&lt;h3 id=&#34;inverted-index倒排索引&#34;&gt;Inverted Index（倒排索引）&lt;/h3&gt;
&lt;p&gt;之前一直听过倒排索引（比如ElasticSearch里面），读完书才发现，倒排索引实际上是全文索引的一种常见的实现。它的概念和B+树的索引是等级的。&lt;/p&gt;
&lt;p&gt;倒排索引有两种具体的表现形式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Inverted File Index，表现形式为（单词，单词所在文档ID）&lt;/li&gt;
&lt;li&gt;Full Inverted Index，表现形式为（单词，（单词所在文档ID，具体位置））&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可以看到，二者的差别主要是后者多存储了一个文档中的具体位置，虽然需要维护额外的存储空间，但也更方便我们迅速找到相应的具体段落。InnoDB中的实现也是基于后者的。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;innodb的实现&#34;&gt;InnoDB的实现&lt;/h2&gt;
&lt;p&gt;InnoDB从1.2.x版本开始支持全文索引。&lt;/p&gt;
&lt;h3 id=&#34;auxiliary-table辅助表&#34;&gt;Auxiliary Table（辅助表）&lt;/h3&gt;
&lt;p&gt;作为索引，肯定需要空间进行存储。对于全文索引来说，存储索引的地方即是&lt;strong&gt;Auxiliary Table&lt;/strong&gt;，即辅助表，一般是用关联数组实现的。InnoDB中的辅助表有两列，分别为&lt;strong&gt;word&lt;/strong&gt;字段和&lt;strong&gt;ilist&lt;/strong&gt;字段，在word字段上设有索引。而ilist，则是前面提到的（文档ID，位置），用来迅速定位。&lt;/p&gt;
&lt;p&gt;在InnoDB中，一共有&lt;strong&gt;六张&lt;/strong&gt;辅助表（为了提高并发性能），每张表根据word的Latin编码进行分区。并且，辅助表持久化在磁盘上。&lt;/p&gt;
&lt;h3 id=&#34;fts-index-cache全文检索索引缓存&#34;&gt;FTS Index Cache（全文检索索引缓存）&lt;/h3&gt;
&lt;p&gt;正如其名，FTS Index Cache作为cache，目的非常单纯，就是为了&lt;strong&gt;提高检索性能&lt;/strong&gt;；采用&lt;strong&gt;红黑树&lt;/strong&gt;实现，根据（word，ilist）进行排序。&lt;/p&gt;
&lt;h4 id=&#34;为什么是红黑树&#34;&gt;为什么是红黑树？&lt;/h4&gt;
&lt;p&gt;书上没有说，我去翻了官方文档也没有具体说明。但其实根据它的特点，我们不难推出：&lt;/p&gt;
&lt;p&gt;FTS Index Cache是存储在&lt;strong&gt;内存&lt;/strong&gt;中的（in-memory）。红黑树相较于AVL树，由于在插入/删除的情况下需要的调整代价更小，所以在面对频繁的删改（这里也是同样）时性能更优。而我们知道，InnoDB使用B+树作为索引结构主要是因为索引存储在磁盘上，为了尽量减少磁盘IO，需要树的高度尽可能低。但是在内存中，没有磁盘IO的限制，红黑树显然具有更大的优势。&lt;/p&gt;
&lt;p&gt;其实，基于在内存中这一前提，很多设计都选择了红黑树，epoll、JDK8的HashMap，由果溯因，也看得出红黑树效率是很高的。&lt;/p&gt;
&lt;h4 id=&#34;和change-buffer对比&#34;&gt;和Change Buffer对比&lt;/h4&gt;
&lt;p&gt;我们知道InnoDB中很多地方使用了缓存，而&lt;strong&gt;Change Buffer&lt;/strong&gt;可以很好的与FTS Index Cache进行类比：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于Change Buffer，每次写入都不立刻持久化到磁盘上（不然也就失去了作为buffer的意义），而往往等到记录的数据页被读入内存中，再进行相应的修改；&lt;/li&gt;
&lt;li&gt;而对于FTS Index Cache也是同样：当对全文检索进行查询时，FTS Index Cache的word字段才被合并到辅助表中，然后再进行查询。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么这样一来，一定会有一个问题：当数据库宕机时，部分FTS Index Cache的数据可能还没有被写入辅助表中。为了解决这个问题，书上是这样描述的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;那么下次重启数据库时，当用户对表进行全文检索（查询或者插入操作）时，InnoDB存储引擎会自动读取未完成的文档，然后进行分词操作，再将分词的结果放入到FTS Index Cache中。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;说白了，就是保留上次的状态，类似于HTTP“断点续传”的功能。但是HTTP断点续传基于头部的range字段，而这里重新开始又基于什么呢？关于这一点，书上并没有给出明确的答复，但是我想，可以通过Redis中相似的操作，进行合理的推论：&lt;/p&gt;
&lt;p&gt;我们知道，Redis中对过期键采取的删除策略是惰性删除和定期删除。其中定期删除的实现由serverCron函数调用activeExpireCycle函数，在规定时间内遍历各个数据库。它内部维护了一个current_db的全局变量，记录当前函数的检查进度。如果此时遍历结束但没有遍历完，下一次再开始时就会从current_db标识的数据库开始，而不是从头开始。&lt;/p&gt;
&lt;p&gt;那么类比一下，这里对于FTS Index Cache的遍历写入就相当于对数据库中过期键的遍历检查。那么，和current_db相同，InnoDB应该也是维护了一个&lt;strong&gt;全局变量&lt;/strong&gt;（当然，肯定需要持久化到磁盘上），记录当前写入的进度，从而使得下次重启时，能够续着上一次的进度进行写入。&lt;/p&gt;
&lt;h3 id=&#34;fts-document-id&#34;&gt;FTS Document ID&lt;/h3&gt;
&lt;p&gt;如果光凭借辅助表中的word和ilist，我们无法直接将需要进行搜索的文本与辅助表进行联系。而&lt;strong&gt;FTS Document ID&lt;/strong&gt;帮助我们完成了这项工作。它的作用，即是在数据表中，和word进行映射。&lt;/p&gt;
&lt;p&gt;在InnoDB中，这一列被命名为FTS_DOC_ID，类型必须为&lt;strong&gt;BIGINT UNSIGNED NOT NULL&lt;/strong&gt;。我们不妨测试一下，自己建一个含有名为FTS_DOC_ID，类型不满足要求的列，不出意外报错：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;[42000][1166] Incorrect column name &amp;#39;FTS_DOC_ID&amp;#39;.
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;我们当然可以手动创建这一列（只要满足类型要求），如果没有手动创建，InnoDB也会为我们自动生成。&lt;/p&gt;
&lt;p&gt;此外，在对文档中的分词进行删除时，InnoDB将不会删除辅助表中的记录，而是只删除FTS Index Cache中的记录，并且将被删除记录的FTS_DOC_ID保存在DELETED auxiliary table中。至于为什么不删除，官方文档做了很好的解释：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/ftindex.png&#34;
	width=&#34;2360&#34;
	height=&#34;422&#34;
	srcset=&#34;https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/ftindex_hucb4517e2464f1b3a73a8c3833b3e3350_253752_480x0_resize_box_3.png 480w, https://example.com/p/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95%E8%AF%A6%E8%A7%A3%E5%9F%BA%E4%BA%8Einnodb%E5%BC%95%E6%93%8E/ftindex_hucb4517e2464f1b3a73a8c3833b3e3350_253752_1024x0_resize_box_3.png 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;全文索引的删除&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;559&#34;
		data-flex-basis=&#34;1342px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;意思就是说对于全文索引进行删除时，会导致辅助表中非常多的细微的改动，也就影响了对于这些表的并发访问。 所以，不对表中数据做真实删改，而是通过将FTS_DOC_ID保存在DELETED auxiliary table中，很好的避免了这个问题。&lt;/p&gt;
&lt;p&gt;实际上，类似的“&lt;strong&gt;懒删除&lt;/strong&gt;”策略在很多地方都有应用，例如Redis中，对于过期键删除采用的策略之一就是惰性删除；对于执行sdstrim之后的SDS也采用了惰性空间释放。&lt;/p&gt;
&lt;p&gt;当然，一直不删除，无效的数据始终堆积在辅助表中，会让表变得非常庞大，占据额外的空间。此时我们就可以通过&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;n&#34;&gt;OPTIMIZE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;TABLE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;来进行删除操作。当然，OPTIMIZE TABLE还有别的一些功能，例如&lt;strong&gt;重新统计基数&lt;/strong&gt;，由于和本文关系不大，这里就不展开了。&lt;/p&gt;
&lt;h3 id=&#34;stopword-list&#34;&gt;Stopword List&lt;/h3&gt;
&lt;p&gt;顾名思义，就是维护了一张表，对于表中的词（大多是没有太大意义的）不进行索引。具体的表在information_schema下的INNODB_FT_DEFAULT_STOPWORD。&lt;/p&gt;
&lt;h3 id=&#34;其他限制&#34;&gt;其他限制&lt;/h3&gt;
&lt;p&gt;书上还列举了当前InnoDB的全文检索的限制：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每张表只能有一个全文检索的索引&lt;/li&gt;
&lt;li&gt;由多列组合而成的全文检索的索引列必须使用相同的字符集与排序规则&lt;/li&gt;
&lt;li&gt;不支持没有单词界定符（delimiter）的语言，如中文、日文、韩语等&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;使用全文检索&#34;&gt;使用全文检索&lt;/h2&gt;
&lt;p&gt;InnoDB中，使用全文索引的进行检索的方式为：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;col2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;...)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;expr&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;search_modifier&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;其中，MATCH指定需要查询的列，AGAINST指定查询方法，有以下三种。&lt;/p&gt;
&lt;h3 id=&#34;natural-language&#34;&gt;Natural Language&lt;/h3&gt;
&lt;p&gt;查询带有指定词的文档，例如查询新闻标题中带有“Covid”的行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Covid&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;IN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NATURAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LANGUAGE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;这一种方法也是InnoDB默认的方法，因而可以简写：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Covid&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;查询返回的结果根据相关性进行降序排序。相关性是一个非负浮点数，计算依据于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;word是否在文档中出现&lt;/li&gt;
&lt;li&gt;word在文档中出现的次数&lt;/li&gt;
&lt;li&gt;word在索引列中的数量&lt;/li&gt;
&lt;li&gt;多少个文档包含该word&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，查询的word长度也需要在[innodb_ft_min_token_size, innodb_ft_max_token_size]之间，默认值分别为3和84。&lt;/p&gt;
&lt;h3 id=&#34;boolean&#34;&gt;Boolean&lt;/h3&gt;
&lt;p&gt;Boolean模式会允许对查询的word进行符号拼接，规则如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;+ 表示该word必须存在；- 相反&lt;/li&gt;
&lt;li&gt;无操作符表示该word可选，如出现则相关性更高&lt;/li&gt;
&lt;li&gt;@distance表示查询的多个单词距离是否在distance之内，单位为字节&lt;/li&gt;
&lt;li&gt;&amp;gt; 表示该word出现时增加相关性； &amp;lt; 相反&lt;/li&gt;
&lt;li&gt;~ 表示该word出现时相关性为负&lt;/li&gt;
&lt;li&gt;* 表示以该单词开头的单词&lt;/li&gt;
&lt;li&gt;&amp;quot; 表示短语&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如查询新闻标题中带有“Covid”但没有“Today”的行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;+Covid -Today&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;IN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;BOOLEAN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;query-expansion&#34;&gt;Query Expansion&lt;/h3&gt;
&lt;p&gt;查询扩展，我的理解是进行二次查询。当条件有限时比较有用。查询分为两个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;根据搜索的word进行全文索引查询&lt;/li&gt;
&lt;li&gt;根据第一阶段产生的分词，再进行一次全文索引的查询&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;例如，先通过NATURAL LANGUAGE模式查询新闻标题中带有“Covid”的行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span class=&#34;k&#34;&gt;SELECT&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;news&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WHERE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MATCH&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;topic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AGAINST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;Covid&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;IN&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;NATURAL&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;LANGUAGE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;MODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;之后再使用QUERY EXPANSION进行查询，得到的结果就是与第一步结果相关的，而非仅仅满足条件的。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>《MySQL技术内幕》读书笔记（1）</title>
        <link>https://example.com/p/innodb_book_1/</link>
        <pubDate>Sun, 06 Mar 2022 16:59:40 +0800</pubDate>
        
        <guid>https://example.com/p/innodb_book_1/</guid>
        <description>&lt;p&gt;2.4 CheckPoint，讲到了CheckPoint解决的问题，其中第三点是“重做日志不可用时，刷新脏页”。详细的描述是这样的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;重做日志可以被重用的部分是指这些重做日志已经不再需要，即当数据库发生宕机时，数据库恢复操作不需要这部分的重做日志，因此这部分就可以被覆盖重用。&lt;strong&gt;若此时重做日志还需要使用，那么必须强制产生CheckPoint，将缓冲池中的页至少刷新到当前重做日志的位置。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;读到这一段的时候，尤其是加粗部分的内容，我不禁产生疑惑：缓冲池中的页不是本来就和redolog状态相同吗？为什么还需要将缓冲池中的页刷新？&lt;/p&gt;
&lt;p&gt;第二天回顾的时候，我思考了一下。&lt;strong&gt;（以下为是个人解读，如有错误欢迎批评指正）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先，由于InnoDB采用WAL搭配redolog保证crash safe，也就是更新数据的时候，先写redolog，再写buffer pool中的数据页。又由于写redolog时需要先写redolog buffer，而这个过程由于&lt;strong&gt;不需要doublewrite&lt;/strong&gt;，应该是比较快的。所以，这就可能导致在数据量大、并发写多的情况下，很多操作都被写到了redolog中，但还没有写到buffer pool中的数据页中，如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://example.com/p/innodb_book_1/redolog&amp;amp;bfpool.jpeg&#34;
	width=&#34;3277&#34;
	height=&#34;999&#34;
	srcset=&#34;https://example.com/p/innodb_book_1/redolog&amp;amp;bfpool_hu9b47d580dc76ef093ae3038fc81ae849_273298_480x0_resize_q75_box.jpeg 480w, https://example.com/p/innodb_book_1/redolog&amp;amp;bfpool_hu9b47d580dc76ef093ae3038fc81ae849_273298_1024x0_resize_q75_box.jpeg 1024w&#34;
	loading=&#34;lazy&#34;
	
		alt=&#34;redolog和buffer pool对比&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;328&#34;
		data-flex-basis=&#34;787px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;而这时，由于redolog是循环写，在空间不足时（写不下了），就产生了书上说的“不可用”状态。&lt;/p&gt;
&lt;p&gt;因此此时，必须强制先将buffer pool中的数据页写入一部分（刷回盘），和redolog保持一致，从而腾出空间。具体的解决措施，即是属于Fuzzy CheckPoint的Async/Sync Flush CheckPoint，根据checkpoint_age，分别和async_water_mark以及sync_water_mark比较，选择相应的Flush操作。具体判断过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当checkpoint_age &amp;lt; async_water_mark时，无需刷页&lt;/li&gt;
&lt;li&gt;当async_water_mark &amp;lt; checkpoint_age &amp;lt; sync_water_mark时，触发Async Flush&lt;/li&gt;
&lt;li&gt;当sync_water_mark &amp;lt; checkpoint_age时，触发Sync Flush（一般很少发生）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中，water_mark的计算公式为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;async_water_mark = 75% * total_redo_log_file_size&lt;/p&gt;
&lt;p&gt;sync_water_mark = 90% * total_redo_log_file_size&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;而checkpoint_age的计算公式为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;checkpoint_age = redo_lsn - checkpoint_lsn&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;LSN即Log Sequence Number，我的理解里，其实就和kafka里的offset作用差不多。&lt;/p&gt;
&lt;p&gt;经过Flush操作之后，确保checkpoint_age &amp;lt; async_water_mark。&lt;/p&gt;
&lt;p&gt;回到刚才的问题，所以，文中的“不可用”，指的应该是&lt;strong&gt;redolog写空间不足&lt;/strong&gt;。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>OpenFeign远程服务调用返回结果时报错 ClassCastException</title>
        <link>https://example.com/p/openfeign%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C%E6%97%B6%E6%8A%A5%E9%94%99-classcastexception/</link>
        <pubDate>Sun, 06 Mar 2022 16:54:56 +0800</pubDate>
        
        <guid>https://example.com/p/openfeign%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%E8%BF%94%E5%9B%9E%E7%BB%93%E6%9E%9C%E6%97%B6%E6%8A%A5%E9%94%99-classcastexception/</guid>
        <description>&lt;p&gt;一开始挺纳闷，我也返回的结果怎么会是LinkedHashMap呢？我代码里也没有用LinkedHashMap封装结果呀？&lt;/p&gt;
&lt;p&gt;上网搜了一下发现：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;​    因为rpc远程调用在底层还是使用的HTTPClient，所以在传递参数的时候，必定要有个顺序，当你传递map的时候map里面的值也要有顺序，不然服务层在接的时候就出问题了，所以它才会从map转为linkedhashMap！spring 有一个类叫ModelMap，继承了linkedhashMap public class ModelMap extends LinkedHashMap ,所以一个接口返回的结果就可以直接用ModelMap来接，注意ModelMap是没有泛型的，不管你返回的结果是什么类型的map，泛型是多复杂的map，都可以直接new一个Modelmap，用它来接返回的结果！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;原文出处：&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/hp_yangpeng/article/details/80592332?ops_request_misc=%7B%22request%5Fid%22%3A%22163915388716780274112741%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&amp;amp;request_id=163915388716780274112741&amp;amp;biz_id=0&amp;amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-80592332.pc_search_result_cache&amp;amp;utm_term=feign&amp;#43;%e8%bf%94%e5%9b%9elinkedhashmap&amp;amp;spm=1018.2226.3001.4187&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;spring cloud远程调用接口返回linkedHashMap问题&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;原来是这样。了解了原因之后，写个结果转换工具类：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ConvertUtil&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;

    &lt;span class=&#34;cm&#34;&gt;/**
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * 获取指定类对象
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * @param result 远程调用结果
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * @param targetClassInstance 指定类对象实例
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     * @return
&lt;/span&gt;&lt;span class=&#34;cm&#34;&gt;     */&lt;/span&gt;
    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;getFeignResult&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Object&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targetClassInstance&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;n&#34;&gt;ObjectMapper&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mapper&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ObjectMapper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 通过ObjectMapper获取映射
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;        &lt;span class=&#34;k&#34;&gt;try&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;Class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;?&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targetClass&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Class&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;forName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;targetClassInstance&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getClass&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getName&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// 获取指定对象类
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;            &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mapper&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;convertValue&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;result&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;targetClass&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;);&lt;/span&gt;
        &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;catch&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ClassNotFoundException&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;n&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;printStackTrace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
        &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;null&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;需要转换的时候，调用即可：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;n&#34;&gt;Student&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;res&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Student&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ConvertUtil&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getFeignResult&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;studentService&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;loginByPassword&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dto&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;getData&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;new&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Student&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        
    </channel>
</rss>
